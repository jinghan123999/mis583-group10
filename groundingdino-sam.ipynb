{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13967443,"sourceType":"datasetVersion","datasetId":8903944},{"sourceId":14054506,"sourceType":"datasetVersion","datasetId":8946302}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport subprocess\nimport sys\n\n# 1. è¨­å®šåŸºç¤è·¯å¾‘\nHOME = os.getcwd()\nos.makedirs(os.path.join(HOME, \"data\"), exist_ok=True)\nos.makedirs(os.path.join(HOME, \"outputs\"), exist_ok=True)\nos.makedirs(os.path.join(HOME, \"weights\"), exist_ok=True)\n\n# 2. é‡å° P100 GPU è¨­å®šæ¶æ§‹\nos.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"6.0\"\nos.environ[\"CUDA_HOME\"] = \"/usr/local/cuda\"\n\nprint(\"ğŸ§¹ æ­¥é©Ÿ 1: å¼·åˆ¶æ¸…ç†èˆ‡å®‰è£ç›¸å®¹ä¾è³´...\")\n\n# 3. ç§»é™¤è¡çªåº« (å¾¹åº•æ¸…é™¤)\npkgs_to_remove = [\"numpy\", \"scipy\", \"torch\", \"torchvision\", \"torchaudio\", \"Pillow\", \"transformers\", \"groundingdino\", \"opencv-python\", \"pycocotools\"]\nsubprocess.run([\"pip\", \"uninstall\", \"-y\"] + pkgs_to_remove)\nsubprocess.run([\"rm\", \"-rf\", \"GroundingDINO\"])\n\n# 4. å®‰è£ PyTorch 2.1.0 (CUDA 12.1)\nprint(\"ğŸ”§ å®‰è£ PyTorch 2.1.0...\")\nsubprocess.run([\n    \"pip\", \"install\", \n    \"torch==2.1.0\", \"torchvision==0.16.0\", \"torchaudio==2.1.0\", \n    \"--index-url\", \"https://download.pytorch.org/whl/cu121\"\n])\n\n# 5. å®‰è£å…¶ä»–ä¾è³´ (é—œéµï¼šPillow 9.5.0)\nprint(\"ğŸ”§ å®‰è£ Numpy < 2.0 èˆ‡ Pillow 9.5.0...\")\nsubprocess.run([\n    \"pip\", \"install\", \n    \"numpy<2.0\", \"scipy==1.13.1\", \"transformers==4.30.2\", \"opencv-python\", \"pycocotools\",\n    \"--ignore-installed\"\n])\n\n# â˜…â˜…â˜… å¼·åˆ¶é–å®š Pillow 9.5.0ï¼Œè§£æ±º is_directory éŒ¯èª¤ â˜…â˜…â˜…\nsubprocess.run([\"pip\", \"install\", \"Pillow==9.5.0\", \"matplotlib==3.7.2\", \"--force-reinstall\"])\n\n# 6. å®‰è£ SAM èˆ‡ Supervision\nsubprocess.run([\"pip\", \"install\", \"git+https://github.com/facebookresearch/segment-anything.git\"])\nsubprocess.run([\"pip\", \"install\", \"supervision==0.6.0\"])\n\nprint(\"âœ… ç’°å¢ƒä¾è³´å®‰è£å®Œæˆï¼è«‹ç¹¼çºŒåŸ·è¡Œ Cell 2ã€‚\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nprint(\"ğŸ“¥ æ­¥é©Ÿ 2: ä¸‹è¼‰ä¸¦ç·¨è­¯ GroundingDINO (é€™éœ€è¦ç´„ 3-5 åˆ†é˜)...\")\n\n# 1. Clone å°ˆæ¡ˆ\nif os.path.exists(\"GroundingDINO\"):\n    !rm -rf GroundingDINO\n!git clone https://github.com/IDEA-Research/GroundingDINO.git\n\n# 2. å¼·åˆ¶è¨­å®šç’°å¢ƒè®Šæ•¸\nos.environ[\"CUDA_HOME\"] = \"/usr/local/cuda\"\nos.environ[\"BUILD_WITH_CUDA\"] = \"1\"\nos.environ[\"AM_I_DOCKER\"] = \"1\"\nos.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"6.0\" \n\n# 3. é–‹å§‹ç·¨è­¯\n%cd GroundingDINO\n!python setup.py install\n%cd {HOME}\n\nprint(\"âœ… GroundingDINO ç·¨è­¯å®Œæˆï¼è«‹åŸ·è¡Œä¸‹ä¸€å€‹ Cellã€‚\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nHOME = os.getcwd()\nWEIGHTS_DIR = os.path.join(HOME, \"weights\")\nos.makedirs(WEIGHTS_DIR, exist_ok=True)\n\nprint(\"â¬‡ï¸ æ­¥é©Ÿ 3: ä¸‹è¼‰æ¨¡å‹æ¬Šé‡...\")\n\nif not os.path.exists(os.path.join(WEIGHTS_DIR, \"groundingdino_swint_ogc.pth\")):\n    !wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth -P {WEIGHTS_DIR}\n\nif not os.path.exists(os.path.join(WEIGHTS_DIR, \"sam_vit_h_4b8939.pth\")):\n    !wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P {WEIGHTS_DIR}\n\nprint(\"âœ… æ¬Šé‡ä¸‹è¼‰å®Œæˆï¼\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\nimport os\n\nprint(\"ğŸš‘ ç·Šæ€¥ä¿®å¾©ç’°å¢ƒä¸­... (æ­£åœ¨å¼·åˆ¶é™ç´š NumPy åˆ° 1.26.4)\")\n\n# 1. å¼·åˆ¶ç§»é™¤ç•¶å‰çš„ numpy (ç„¡è«–å®ƒæ˜¯ä»€éº¼ç‰ˆæœ¬)\nsubprocess.run([\"pip\", \"uninstall\", \"-y\", \"numpy\"])\n\n# 2. å¼·åˆ¶å®‰è£æŒ‡å®šçš„èˆŠç‰ˆæœ¬\n# ä½¿ç”¨ --no-deps åƒæ•¸ï¼Œå« pip é–‰å˜´ï¼Œä¸è¦æª¢æŸ¥ç›¸å®¹æ€§ï¼Œç›´æ¥è£å°±å°äº†\nsubprocess.run([\"pip\", \"install\", \"numpy==1.26.4\", \"--no-deps\", \"--force-reinstall\"])\n\n# 3. ç¢ºä¿ Matplotlib ä¹Ÿæ˜¯èˆŠç‰ˆ\nsubprocess.run([\"pip\", \"install\", \"matplotlib==3.7.2\", \"--no-deps\", \"--force-reinstall\"])\n\nprint(\"âœ… ä¿®å¾©æŒ‡ä»¤åŸ·è¡Œå®Œç•¢ï¼\")\nprint(\"â— é‡è¦ï¼šè«‹å‹™å¿…åŸ·è¡Œä¸‹ä¸€æ­¥ã€é‡å•Ÿ Sessionã€ï¼Œå¦å‰‡è¨˜æ†¶é«”ä¸­çš„èˆŠç‰ˆ NumPy ä¸æœƒæ¶ˆå¤±ã€‚\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport sys\nimport os\n\n# å¼·åˆ¶ç¢ºä¿ Python æ‰¾å¾—åˆ° GroundingDINO\ncwd = os.getcwd()\nif os.path.join(cwd, \"GroundingDINO\") not in sys.path:\n    sys.path.append(os.path.join(cwd, \"GroundingDINO\"))\n\nprint(\"ğŸ§  æ­¥é©Ÿ 4: å˜—è©¦è¼‰å…¥æ¨¡å‹...\")\n\ntry:\n    from groundingdino.util.inference import load_model, load_image, predict\n    from segment_anything import SamPredictor, sam_model_registry\n    print(\"   âœ… æˆåŠŸåŒ¯å…¥å‡½å¼åº«ï¼\")\nexcept ImportError as e:\n    print(f\"âŒ åŒ¯å…¥å¤±æ•—: {e}\")\n    raise e\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"   ä½¿ç”¨é‹ç®—è£ç½®: {DEVICE}\")\n\n# 1. è¼‰å…¥ GroundingDINO\nHOME = os.getcwd()\nWEIGHTS_DIR = os.path.join(HOME, \"weights\")\nGD_CONFIG = os.path.join(HOME, \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\nGD_CHECKPOINT = os.path.join(WEIGHTS_DIR, \"groundingdino_swint_ogc.pth\")\n\ngrounding_dino_model = load_model(GD_CONFIG, GD_CHECKPOINT)\n\n# 2. è¼‰å…¥ SAM\nSAM_CHECKPOINT = os.path.join(WEIGHTS_DIR, \"sam_vit_h_4b8939.pth\")\nsam = sam_model_registry[\"vit_h\"](checkpoint=SAM_CHECKPOINT).to(DEVICE)\nsam_predictor = SamPredictor(sam)\n\nprint(\"\\nğŸ‰ æ­å–œï¼æ¨¡å‹è¼‰å…¥æˆåŠŸï¼\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport supervision as sv\nimport matplotlib.pyplot as plt\nimport torch\n# é—œéµä¿®æ­£ï¼šå¾ GroundingDINO åŒ¯å…¥åº§æ¨™è½‰æ›å·¥å…·\nfrom groundingdino.util.box_ops import box_cxcywh_to_xyxy\n\ndef run_grounded_sam(image_path, text_prompt, box_threshold=0.35, text_threshold=0.25):\n    image_source, image = load_image(image_path)\n    \n    # 1. GroundingDINO: Text -> Box\n    boxes, logits, phrases = predict(\n        model=grounding_dino_model,\n        image=image,\n        caption=text_prompt,\n        box_threshold=box_threshold,\n        text_threshold=text_threshold\n    )\n    \n    if len(boxes) == 0:\n        return image_source, None, None, None\n\n    # 2. åº§æ¨™è½‰æ› (ä¿®æ­£é»)\n    h, w, _ = image_source.shape\n    boxes_xyxy = boxes * torch.Tensor([w, h, w, h])\n    boxes_xyxy = box_cxcywh_to_xyxy(boxes_xyxy).numpy()\n    \n    # 3. SAM: Box -> Mask\n    sam_predictor.set_image(image_source)\n    transformed_boxes = sam_predictor.transform.apply_boxes_torch(\n        torch.as_tensor(boxes_xyxy, device=DEVICE), \n        image_source.shape[:2]\n    )\n    \n    masks, _, _ = sam_predictor.predict_torch(\n        point_coords=None,\n        point_labels=None,\n        boxes=transformed_boxes,\n        multimask_output=False,\n    )\n    return image_source, boxes_xyxy, masks, phrases\n\ndef plot_result(image, boxes, masks, phrases):\n    box_annotator = sv.BoxAnnotator()\n    mask_annotator = sv.MaskAnnotator()\n    detections = sv.Detections(\n        xyxy=boxes, \n        mask=masks.cpu().numpy().squeeze(1), \n        class_id=np.arange(len(boxes))\n    )\n    labels = [f\"{phrase}\" for phrase in phrases]\n    annotated_image = mask_annotator.annotate(scene=image.copy(), detections=detections)\n    annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)\n    \n    # é¡¯ç¤ºåœ–ç‰‡ (å¯é¸ï¼Œæ‰¹é‡è·‘æ™‚å¯ä»¥è¨»è§£æ‰ä»¥å…å¤ªä½”ç‰ˆé¢)\n    # plt.figure(figsize=(10, 10))\n    # plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n    # plt.axis('off')\n    # plt.show()\n    \n    return annotated_image\n\nprint(\"âœ… Pipeline å®šç¾©å®Œæˆ (ä¿®æ­£ç‰ˆ)ï¼\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport shutil\n\n# --- è¨­å®šæ‚¨çš„è³‡æ–™é›†è·¯å¾‘ (è«‹ä¿®æ”¹é€™è£¡ï¼) ---\n# å‡è¨­æ‚¨ä¸Šå‚³çš„è³‡æ–™é›†åç¨±æ˜¯ \"my-custom-dataset\"\n# è·¯å¾‘é€šå¸¸é•·é€™æ¨£: \"/kaggle/input/my-custom-dataset\"\nINPUTimg_ROOT = \"/kaggle/input/redataset/val2017_50\"\nINPUTjson_ROOT = \"/kaggle/input/redataset\"\n\n# è¨­å®šæ‚¨çš„åœ–ç‰‡è³‡æ–™å¤¾åç¨±èˆ‡ JSON æª”å\nUSER_IMAGE_DIR = os.path.join(INPUTimg_ROOT, \"val2017_50\")  # å¦‚æœåœ–ç‰‡ç›´æ¥åœ¨æ ¹ç›®éŒ„ï¼Œå°±æ”¹æˆ INPUT_ROOT\nUSER_JSON_PATH = os.path.join(INPUTjson_ROOT, \"val2017_prompt.json\")\n\n# è¨­å®šè¼¸å‡ºå·¥ä½œç›®éŒ„\nHOME = os.getcwd()\nOUTPUT_DIR = os.path.join(HOME, \"outputs\")\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(f\"ğŸ“‚ æº–å‚™è®€å–ä½¿ç”¨è€…è³‡æ–™é›†...\")\nprint(f\"   åœ–ç‰‡ä¾†æº: {USER_IMAGE_DIR}\")\nprint(f\"   Promptè¨­å®šæª”: {USER_JSON_PATH}\")\n\n# æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨\nif not os.path.exists(USER_JSON_PATH):\n    print(f\"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° {USER_JSON_PATH}ï¼Œè«‹æª¢æŸ¥è·¯å¾‘æˆ–æ˜¯æª”åæ˜¯å¦æ­£ç¢ºã€‚\")\nelse:\n    with open(USER_JSON_PATH, 'r') as f:\n        data = json.load(f)\n    print(f\"âœ… æˆåŠŸè®€å– JSONï¼å…±åŒ…å« {len(data)} ç­†è³‡æ–™ã€‚\")\n    print(f\"   ç¬¬ä¸€ç­†ç¯„ä¾‹: {data[0]}\")\n    \n    # æª¢æŸ¥ç¬¬ä¸€å¼µåœ–æ˜¯å¦å­˜åœ¨\n    first_img_path = os.path.join(USER_IMAGE_DIR, data[0]['image_filename'])\n    if os.path.exists(first_img_path):\n        print(f\"âœ… åœ–ç‰‡è·¯å¾‘æª¢æŸ¥é€šé: {first_img_path}\")\n        print(\"è«‹ç¹¼çºŒåŸ·è¡Œ Cell 7 é€²è¡Œæ¨è«–ï¼\")\n    else:\n        print(f\"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°ç¬¬ä¸€å¼µåœ–ç‰‡ {first_img_path}\")\n        print(\"   è«‹ç¢ºèª JSON ä¸­çš„ file_name æ˜¯å¦èˆ‡è³‡æ–™å¤¾å…§çš„å¯¦éš›æª”åä¸€è‡´ã€‚\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport json\nimport torch\nimport numpy as np\nimport supervision as sv\nimport matplotlib.pyplot as plt\nimport zipfile\nimport shutil  # <--- æ–°å¢é€™å€‹\nfrom groundingdino.util.box_ops import box_cxcywh_to_xyxy\n\n# --- 1. è¨­å®šè·¯å¾‘ ---\nINPUTimg_ROOT = \"/kaggle/input/redataset/val2017_50\"\nINPUTjson_ROOT = \"/kaggle/input/redataset\"\nUSER_JSON_PATH = os.path.join(INPUTjson_ROOT, \"val2017_prompt.json\")\nUSER_IMAGE_DIR = os.path.join(INPUTimg_ROOT, \"val2017_50\")\nHOME = os.getcwd()\nOUTPUT_DIR = os.path.join(HOME, \"outputs\")\n\n# â˜…â˜…â˜… é—œéµä¿®æ­£ï¼šåŸ·è¡Œå‰å…ˆæ¸…ç©ºè¼¸å‡ºè³‡æ–™å¤¾ â˜…â˜…â˜…\nif os.path.exists(OUTPUT_DIR):\n    shutil.rmtree(OUTPUT_DIR) # åˆªé™¤æ•´å€‹è³‡æ–™å¤¾\nos.makedirs(OUTPUT_DIR, exist_ok=True) # é‡æ–°å»ºç«‹ç©ºçš„\nprint(f\"ğŸ§¹ å·²æ¸…ç©º {OUTPUT_DIR}ï¼Œæº–å‚™å­˜æ”¾æ–°çµæœ...\")\n# ------------------------------------------\n\n# PROMPT_TYPE = 'coarse'\n# PROMPT_TYPE = 'attribute'\nPROMPT_TYPE = 'fine_grained'\n\nprint(f\"ğŸš€ æ­¥é©Ÿ 7: é–‹å§‹æ‰¹é‡æ¨è«–èˆ‡ç”¢åœ–...\")\n# ... (ä»¥ä¸‹ç¨‹å¼ç¢¼ä¿æŒä¸è®Š) ...\n\n# æª¢æŸ¥è·¯å¾‘\nif not os.path.exists(USER_JSON_PATH):\n    print(f\"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° JSON æª” {USER_JSON_PATH}\")\nelif not os.path.exists(USER_IMAGE_DIR):\n    if os.path.exists(INPUTimg_ROOT):\n        USER_IMAGE_DIR = INPUTimg_ROOT\n        print(f\"âš ï¸ è·¯å¾‘ä¿®æ­£ï¼šæ”¹ç‚ºä½¿ç”¨ {USER_IMAGE_DIR}\")\n    else:\n        print(f\"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åœ–ç‰‡è³‡æ–™å¤¾ {USER_IMAGE_DIR}\")\n\nif os.path.exists(USER_JSON_PATH) and os.path.exists(USER_IMAGE_DIR):\n    with open(USER_JSON_PATH, 'r', encoding='utf-8') as f:\n        image_data_list = json.load(f)\n\n    success_count = 0\n\n    for idx, item in enumerate(image_data_list):\n        file_name = item['image_filename']\n        try:\n            prompt = item['prompts'][PROMPT_TYPE]\n        except KeyError:\n            continue\n\n        img_path = os.path.join(USER_IMAGE_DIR, file_name)\n        \n        print(f\"[{idx+1}/{len(image_data_list)}] è™•ç†: {file_name} ...\", end=\" \")\n        \n        if not os.path.exists(img_path):\n            print(\"âŒ æ‰¾ä¸åˆ°åœ–ç‰‡\")\n            continue\n\n        try:\n            # A. Pipeline\n            image_source, boxes, masks, phrases = run_grounded_sam(\n                image_path=img_path, \n                text_prompt=prompt, \n                box_threshold=0.35, \n                text_threshold=0.25\n            )\n            \n            # B. ç¹ªåœ–å­˜æª”\n            if boxes is not None and len(boxes) > 0:\n                res = plot_result(image_source, boxes, masks, phrases)\n                save_name = f\"result_{os.path.splitext(file_name)[0]}.png\"\n                cv2.imwrite(os.path.join(OUTPUT_DIR, save_name), res)\n                print(\"âœ… å®Œæˆ\")\n                success_count += 1\n            else:\n                print(\"âš ï¸ æœªåµæ¸¬åˆ°ç‰©ä»¶\")\n                \n        except Exception as e:\n            print(f\"âŒ å¤±æ•—: {e}\")\n\n    # æ‰“åŒ…\n    print(\"\\n\" + \"=\"*40)\n    print(f\"ğŸ“Š è™•ç†å®Œæˆï¼æˆåŠŸç”¢å‡º {success_count} å¼µåœ–ç‰‡\")\n\n    # zip_name = \"coarse_results.zip\"\n    # zip_name = \"attribute_results.zip\"\n    zip_name = \"fine_grained_results.zip\" # æ”¹å€‹åå­—å€åˆ†\n    print(f\"ğŸ“¦ æ­£åœ¨æ‰“åŒ…æˆ {zip_name} ...\")\n    \n    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zf:\n        for file_name in os.listdir(OUTPUT_DIR):\n            if file_name.endswith(\".png\"):\n                full_path = os.path.join(OUTPUT_DIR, file_name)\n                zf.write(full_path, arcname=file_name)\n                \n    print(f\"âœ¨ å…¨éƒ¨å®Œæˆï¼è«‹ä¸‹è¼‰ '{zip_name}' (å·²ç„¡é›œæª”)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport sys\nimport subprocess\nimport json\nimport numpy as np\nimport torch\nimport cv2\nfrom pycocotools.coco import COCO\n\n# --- 0. è‡ªå‹•ä¿®å¾© Protobuf ---\ntry:\n    import google.protobuf\n    if google.protobuf.__version__ != '3.20.3':\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"protobuf==3.20.3\"])\nexcept ImportError:\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"protobuf==3.20.3\"])\n\n# --- 1. è£œä¸Šå¿…è¦çš„åŒ¯å…¥èˆ‡å‡½å¼å®šç¾© (è§£æ±º NameError) ---\ntry:\n    from groundingdino.util.inference import load_image, predict, annotate\n    from groundingdino.util.box_ops import box_cxcywh_to_xyxy\nexcept ImportError:\n    print(\"âš ï¸ åš´é‡è­¦å‘Šï¼šç„¡æ³•åŒ¯å…¥ GroundingDINOã€‚è«‹ç¢ºèªæ‚¨æ˜¯å¦å·²åŸ·è¡Œå®‰è£æ­¥é©Ÿï¼Ÿ\")\n\n# â˜…â˜…â˜… é€™è£¡è£œä¸Šäº†æ‚¨ç¼ºå¤±çš„ run_grounded_sam å‡½å¼ â˜…â˜…â˜…\ndef run_grounded_sam(image_path, text_prompt, box_threshold, text_threshold):\n    # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²è¼‰å…¥\n    if 'grounding_dino_model' not in globals() or 'sam_predictor' not in globals():\n        raise NameError(\"æ¨¡å‹æœªè¼‰å…¥ï¼è«‹å…ˆåŸ·è¡Œä¹‹å‰çš„ Cell (Cell 4) ä¾†è¼‰å…¥ GroundingDINO å’Œ SAM æ¨¡å‹ã€‚\")\n\n    image_source, image = load_image(image_path)\n    \n    # 1. GroundingDINO æ¨è«–\n    boxes, logits, phrases = predict(\n        model=grounding_dino_model,\n        image=image,\n        caption=text_prompt,\n        box_threshold=box_threshold,\n        text_threshold=text_threshold\n    )\n    \n    # å¦‚æœæ²’åµæ¸¬åˆ°æ±è¥¿\n    if len(boxes) == 0:\n        return image_source, None, None, None\n\n    # 2. åº§æ¨™è½‰æ› (Box -> SAM Ready)\n    h, w, _ = image_source.shape\n    boxes_xyxy = boxes * torch.Tensor([w, h, w, h])\n    boxes_xyxy = box_cxcywh_to_xyxy(boxes_xyxy).numpy()\n    \n    # 3. SAM æ¨è«–\n    sam_predictor.set_image(image_source)\n    transformed_boxes = sam_predictor.transform.apply_boxes_torch(\n        torch.as_tensor(boxes_xyxy, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')), \n        image_source.shape[:2]\n    )\n    \n    masks, _, _ = sam_predictor.predict_torch(\n        point_coords=None,\n        point_labels=None,\n        boxes=transformed_boxes,\n        multimask_output=False,\n    )\n    return image_source, boxes_xyxy, masks, phrases\n\n# ==========================================\n# 2. è¨­å®šè·¯å¾‘ (Val2017)\n# ==========================================\nINPUTimg_ROOT = \"/kaggle/input/redataset/val2017_50\"\nINPUTjson_ROOT = \"/kaggle/input/redataset\"\nUSER_JSON_PATH = os.path.join(INPUTjson_ROOT, \"val2017_prompt.json\")\n\n# è·¯å¾‘é˜²å‘†\nPOSSIBLE_SUBDIR = os.path.join(INPUTimg_ROOT, \"val2017_50\")\nif os.path.exists(POSSIBLE_SUBDIR):\n    USER_IMAGE_DIR = POSSIBLE_SUBDIR\n    print(f\"âœ… è‡ªå‹•ä¿®æ­£åœ–ç‰‡è·¯å¾‘: {USER_IMAGE_DIR}\")\nelse:\n    USER_IMAGE_DIR = INPUTimg_ROOT\n    print(f\"âœ… åœ–ç‰‡è·¯å¾‘: {USER_IMAGE_DIR}\")\n\n# ==========================================\n# 3. æº–å‚™ Ground Truth\n# ==========================================\nHOME = os.getcwd()\nDATA_DIR = os.path.join(HOME, \"data\")\nANN_FILE_VAL = os.path.join(DATA_DIR, \"annotations\", \"instances_val2017.json\")\n\n# è‡ªå‹•è£œä¸‹è¼‰\nif not os.path.exists(ANN_FILE_VAL):\n    print(\"â¬‡ï¸ æ­£åœ¨è£œä¸‹è¼‰ COCO æ¨™è¨»æª”...\")\n    os.makedirs(os.path.join(DATA_DIR, \"annotations\"), exist_ok=True)\n    os.system(f\"wget -q http://images.cocodataset.org/annotations/annotations_trainval2017.zip -O {DATA_DIR}/annotations.zip\")\n    os.system(f\"unzip -q {DATA_DIR}/annotations.zip -d {DATA_DIR}\")\n\n# ==========================================\n# 4. åŸ·è¡Œè©•ä¼°\n# ==========================================\nif not os.path.exists(USER_JSON_PATH):\n    print(f\"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° JSON æª” {USER_JSON_PATH}\")\nelif 'grounding_dino_model' not in globals():\n    print(\"âŒ éŒ¯èª¤ï¼šæ¨¡å‹è®Šæ•¸ä¸å­˜åœ¨ã€‚è«‹å¾€å›æ²å‹•ï¼ŒåŸ·è¡Œ **Cell 4 (è¼‰å…¥æ¨¡å‹)** å¾Œå†å›ä¾†åŸ·è¡Œæ­¤ Cellã€‚\")\nelse:\n    coco_api = COCO(ANN_FILE_VAL)\n    \n    with open(USER_JSON_PATH, 'r', encoding='utf-8') as f:\n        image_data_list = json.load(f)\n\n    print(f\"ğŸ“Š æº–å‚™è©•ä¼° {len(image_data_list)} å¼µåœ–ç‰‡...\")\n    \n    scores = {\"iou\": [], \"precision\": [], \"recall\": [], \"dice\": []}\n    PROMPT_TYPE = 'attribute' \n\n    # æŒ‡æ¨™è¨ˆç®—\n    def calculate_metrics(pred_mask, gt_mask):\n        pred = pred_mask > 0\n        gt = gt_mask > 0\n        intersection = np.logical_and(pred, gt).sum()\n        union = np.logical_or(pred, gt).sum()\n        tp = intersection\n        fp = np.logical_and(pred, ~gt).sum()\n        fn = np.logical_and(~pred, gt).sum()\n        \n        iou = intersection / union if union > 0 else 0.0\n        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n        dice = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0.0\n        return iou, precision, recall, dice\n\n    valid_count = 0\n\n    for idx, item in enumerate(image_data_list):\n        file_name = item['image_filename']\n        img_id = item.get('coco_original_id')\n        \n        try:\n            prompt = item['prompts'][PROMPT_TYPE]\n        except: continue \n\n        img_path = os.path.join(USER_IMAGE_DIR, file_name)\n        # æª”åè·¯å¾‘ä¿®æ­£\n        if not os.path.exists(img_path):\n            img_path = os.path.join(USER_IMAGE_DIR, os.path.basename(file_name))\n            if not os.path.exists(img_path): continue\n\n        # A. å–å¾— GT\n        if img_id not in coco_api.imgs: continue\n        ann_ids = coco_api.getAnnIds(imgIds=img_id)\n        anns = coco_api.loadAnns(ann_ids)\n        \n        image_source, _ = load_image(img_path)\n        h, w, _ = image_source.shape\n        gt_mask_all = np.zeros((h, w), dtype=np.uint8)\n        \n        has_valid_gt = False\n        for ann in anns:\n            cat_name = coco_api.loadCats(ann['category_id'])[0]['name']\n            is_match = (cat_name.lower() in prompt.lower()) or \\\n                       (prompt.lower().find(cat_name.lower()) != -1) or \\\n                       (\"public transit bus\" in prompt.lower() and \"bus\" in cat_name.lower())\n\n            if is_match:\n                mask = coco_api.annToMask(ann)\n                gt_mask_all = np.maximum(gt_mask_all, mask)\n                has_valid_gt = True\n        \n        if not has_valid_gt: continue\n        valid_count += 1\n\n        # B. æ¨è«–\n        try:\n            # é€™è£¡å‘¼å«å‰›å‰›è£œä¸Šçš„å‡½å¼\n            _, _, masks, _ = run_grounded_sam(\n                image_path=img_path, text_prompt=prompt, \n                box_threshold=0.35, text_threshold=0.25\n            )\n            pred_mask_all = np.zeros((h, w), dtype=np.uint8)\n            if masks is not None and len(masks) > 0:\n                for m in masks.cpu().numpy().squeeze(1):\n                    pred_mask_all = np.maximum(pred_mask_all, m.astype(np.uint8))\n        except Exception as e:\n            print(f\"âŒ æ¨è«–éŒ¯èª¤: {e}\")\n            pred_mask_all = np.zeros((h, w), dtype=np.uint8)\n\n        # C. ç®—åˆ†\n        iou, prec, rec, dice = calculate_metrics(pred_mask_all, gt_mask_all)\n        scores['iou'].append(iou)\n        scores['precision'].append(prec)\n        scores['recall'].append(rec)\n        scores['dice'].append(dice)\n        \n        if valid_count % 10 == 0:\n            print(f\"  [é€²åº¦ {idx+1}] Valid IoU: {iou:.3f} | Dice: {dice:.3f}\")\n\n    # è¼¸å‡º\n    if len(scores['iou']) > 0:\n        print(\"\\n\" + \"=\"*40)\n        print(f\"ğŸ† æœ€çµ‚è©•ä¼°å ±å‘Š (ä½¿ç”¨ {PROMPT_TYPE} æç¤º)\")\n        print(f\"   æœ‰æ•ˆæ¨£æœ¬æ•¸: {len(scores['iou'])} / {len(image_data_list)}\")\n        print(\"-\" * 40)\n        print(f\"1. Mean IoU (é‡ç–Šåº¦):       {np.mean(scores['iou']):.4f}\")\n        print(f\"2. Mean Precision (æº–ç¢ºç‡): {np.mean(scores['precision']):.4f}\")\n        print(f\"3. Mean Recall (å¬å›ç‡):    {np.mean(scores['recall']):.4f}\")\n        print(f\"4. Mean Dice (F1-Score):   {np.mean(scores['dice']):.4f}\")\n        print(\"=\"*40)\n    else:\n        print(\"âŒ ä¾ç„¶æ²’æœ‰æœ‰æ•ˆæ¨£æœ¬ã€‚\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# è¨­å®šå­˜æª”è·¯å¾‘\nHOME = os.getcwd()\nOUTPUT_DIR = os.path.join(HOME, \"outputs\")\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(\"ğŸš€ æ­¥é©Ÿ 9: æ­£åœ¨ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨...\")\n\n# æª¢æŸ¥æ˜¯å¦æœ‰åˆ†æ•¸æ•¸æ“š\nif 'scores' not in globals() or len(scores['iou']) == 0:\n    print(\"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åˆ†æ•¸æ•¸æ“šã€‚è«‹å…ˆæˆåŠŸåŸ·è¡Œ Cell 8 è¨ˆç®—å‡º IoUã€‚\")\nelse:\n    # --- 1. ç¹ªè£½å¹³å‡åˆ†æ•¸é•·æ¢åœ– (Bar Chart) ---\n    metrics_name = ['IoU', 'Precision', 'Recall', 'Dice']\n    metrics_mean = [\n        np.mean(scores['iou']),\n        np.mean(scores['precision']),\n        np.mean(scores['recall']),\n        np.mean(scores['dice'])\n    ]\n    colors = ['#4c72b0', '#55a868', '#c44e52', '#8172b3'] # å°ˆæ¥­é…è‰²\n\n    plt.figure(figsize=(10, 6))\n    bars = plt.bar(metrics_name, metrics_mean, color=colors, alpha=0.85, width=0.6)\n\n    # æ¨™ä¸Šæ•¸å€¼\n    for bar in bars:\n        height = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n                 f'{height:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n\n    plt.ylim(0, 1.0) # Yè»¸å›ºå®š 0~1\n    plt.title('Grounded-SAM Performance Metrics (Mean)', fontsize=15)\n    plt.ylabel('Score', fontsize=12)\n    plt.grid(axis='y', linestyle='--', alpha=0.5)\n    \n    # å­˜æª”\n    bar_path = os.path.join(OUTPUT_DIR, \"metrics_bar_chart.png\")\n    plt.savefig(bar_path, dpi=300, bbox_inches='tight')\n    plt.show()\n    print(f\"ğŸ“Š é•·æ¢åœ–å·²å„²å­˜: {bar_path}\")\n\n    # --- 2. ç¹ªè£½åˆ†ä½ˆç®±å‹åœ– (Box Plot) ---\n    # é€™å¼µåœ–èƒ½é¡¯ç¤ºæ¨¡å‹ç©©å®šæ€§\n    data_to_plot = [scores['iou'], scores['precision'], scores['recall'], scores['dice']]\n\n    plt.figure(figsize=(10, 6))\n    box = plt.boxplot(data_to_plot, labels=metrics_name, patch_artist=True, \n                      medianprops=dict(color=\"black\", linewidth=1.5))\n\n    # å¹«ç®±å­ä¸Šè‰²\n    for patch, color in zip(box['boxes'], colors):\n        patch.set_facecolor(color)\n        patch.set_alpha(0.6)\n\n    plt.title('Distribution of Evaluation Metrics (N=46)', fontsize=15)\n    plt.ylabel('Score', fontsize=12)\n    plt.grid(axis='y', linestyle='--', alpha=0.5)\n    \n    # å­˜æª”\n    box_path = os.path.join(OUTPUT_DIR, \"metrics_boxplot.png\")\n    plt.savefig(box_path, dpi=300, bbox_inches='tight')\n    plt.show()\n    print(f\"ğŸ“¦ ç®±å‹åœ–å·²å„²å­˜: {box_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pycocotools.coco import COCO\n\n# --- 1. è¨­å®šè·¯å¾‘ ---\nINPUTimg_ROOT = \"/kaggle/input/redataset/val2017_50\"\nINPUTjson_ROOT = \"/kaggle/input/redataset\"\nUSER_JSON_PATH = os.path.join(INPUTjson_ROOT, \"val2017_prompt.json\")\n\n# åœ–ç‰‡è·¯å¾‘è‡ªå‹•åµæ¸¬\nPOSSIBLE_SUBDIR = os.path.join(INPUTimg_ROOT, \"val2017_50\")\nUSER_IMAGE_DIR = POSSIBLE_SUBDIR if os.path.exists(POSSIBLE_SUBDIR) else INPUTimg_ROOT\n\n# Ground Truth æº–å‚™\nHOME = os.getcwd()\nANN_FILE_VAL = os.path.join(HOME, \"data\", \"annotations\", \"instances_val2017.json\")\nOUTPUT_DIR = os.path.join(HOME, \"outputs\")\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# ç¢ºä¿ GroundingDINO å‡½å¼å¯ç”¨\ntry:\n    from groundingdino.util.inference import load_image\nexcept:\n    print(\"âš ï¸ è«‹å…ˆåŸ·è¡Œå‰é¢çš„ Cell ä»¥è¼‰å…¥å¿…è¦å‡½å¼ï¼\")\n\n# --- 2. å®šç¾©è©•ä¼°æµç¨‹ ---\ndef evaluate_prompt_type(prompt_type, image_data, coco_api):\n    print(f\"\\nğŸš€ æ­£åœ¨è©•ä¼° Prompt é¡å‹: ã€{prompt_type}ã€‘...\")\n    scores = {\"iou\": [], \"precision\": [], \"recall\": [], \"dice\": []}\n    \n    # è¨ˆç®—æŒ‡æ¨™å‡½å¼\n    def calculate_metrics(pred_mask, gt_mask):\n        pred = pred_mask > 0\n        gt = gt_mask > 0\n        intersection = np.logical_and(pred, gt).sum()\n        union = np.logical_or(pred, gt).sum()\n        tp = intersection\n        fp = np.logical_and(pred, ~gt).sum()\n        fn = np.logical_and(~pred, gt).sum()\n        \n        iou = intersection / union if union > 0 else 0.0\n        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n        dice = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0.0\n        return iou, precision, recall, dice\n\n    valid_cnt = 0\n    for item in image_data:\n        file_name = item['image_filename']\n        img_id = item.get('coco_original_id')\n        \n        # å–å¾—å°æ‡‰ç²’åº¦çš„ Prompt\n        try:\n            prompt = item['prompts'][prompt_type]\n        except: continue\n\n        img_path = os.path.join(USER_IMAGE_DIR, file_name)\n        if not os.path.exists(img_path):\n            img_path = os.path.join(USER_IMAGE_DIR, os.path.basename(file_name))\n            if not os.path.exists(img_path): continue\n\n        if img_id not in coco_api.imgs: continue\n        \n        # å–å¾— GT\n        ann_ids = coco_api.getAnnIds(imgIds=img_id)\n        anns = coco_api.loadAnns(ann_ids)\n        image_source, _ = load_image(img_path)\n        h, w, _ = image_source.shape\n        gt_mask_all = np.zeros((h, w), dtype=np.uint8)\n        \n        has_gt = False\n        for ann in anns:\n            cat_name = coco_api.loadCats(ann['category_id'])[0]['name']\n            # å¯¬é¬†æ¯”å°\n            if cat_name.lower() in prompt.lower() or prompt.lower().find(cat_name.lower()) != -1 or (\"bus\" in cat_name and \"bus\" in prompt):\n                mask = coco_api.annToMask(ann)\n                gt_mask_all = np.maximum(gt_mask_all, mask)\n                has_gt = True\n        \n        if not has_gt: continue\n        valid_cnt += 1\n\n        # æ¨è«–\n        try:\n            _, _, masks, _ = run_grounded_sam(img_path, prompt, 0.35, 0.25)\n            pred_mask_all = np.zeros((h, w), dtype=np.uint8)\n            if masks is not None and len(masks) > 0:\n                for m in masks.cpu().numpy().squeeze(1):\n                    pred_mask_all = np.maximum(pred_mask_all, m.astype(np.uint8))\n        except:\n            pred_mask_all = np.zeros((h, w), dtype=np.uint8)\n\n        # ç®—åˆ†\n        iou, prec, rec, dice = calculate_metrics(pred_mask_all, gt_mask_all)\n        scores['iou'].append(iou)\n        scores['precision'].append(prec)\n        scores['recall'].append(rec)\n        scores['dice'].append(dice)\n\n    # å›å‚³å¹³å‡åˆ†\n    return {\n        \"Mean IoU\": np.mean(scores['iou']),\n        \"Mean Precision\": np.mean(scores['precision']),\n        \"Mean Recall\": np.mean(scores['recall']),\n        \"Mean Dice\": np.mean(scores['dice'])\n    }\n\n# --- 3. åŸ·è¡Œä¸»ç¨‹å¼ ---\nif not os.path.exists(ANN_FILE_VAL):\n    print(\"âŒ è«‹å…ˆä¸‹è¼‰ COCO æ¨™è¨»æª”\")\nelse:\n    coco_api = COCO(ANN_FILE_VAL)\n    with open(USER_JSON_PATH, 'r') as f:\n        data_list = json.load(f)\n\n    # å®šç¾©è¦æ¯”è¼ƒçš„ç²’åº¦\n    prompt_types = ['coarse', 'attribute', 'fine_grained']\n    final_results = {}\n\n    for p_type in prompt_types:\n        final_results[p_type] = evaluate_prompt_type(p_type, data_list, coco_api)\n\n    # --- 4. ç”Ÿæˆåœ–è¡¨èˆ‡å ±å‘Š ---\n    print(\"\\n\" + \"=\"*50)\n    print(\"ğŸ† ä¸åŒç²’åº¦ Prompt æ•ˆèƒ½æ¯”è¼ƒå ±å‘Š\")\n    print(\"=\"*50)\n    \n    # è½‰æˆ DataFrame é¡¯ç¤ºè¡¨æ ¼\n    df = pd.DataFrame(final_results).T\n    print(df)\n    \n    # ç¹ªè£½é•·æ¢æ¯”è¼ƒåœ–\n    df.plot(kind='bar', figsize=(10, 6), width=0.8, colormap='viridis')\n    plt.title(\"Performance Comparison by Prompt Granularity\", fontsize=15)\n    plt.ylabel(\"Score (0-1)\", fontsize=12)\n    plt.xticks(rotation=0, fontsize=11)\n    plt.ylim(0, 1.0)\n    plt.grid(axis='y', linestyle='--', alpha=0.5)\n    plt.legend(loc='lower right')\n    \n    save_path = os.path.join(OUTPUT_DIR, \"prompt_granularity_comparison.png\")\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    print(f\"âœ… æ¯”è¼ƒåœ–è¡¨å·²å„²å­˜è‡³: {save_path}\")\n    print(\"ğŸ‘‰ é€™å¼µåœ–å¯ä»¥ç”¨ä¾†å›ç­”æ‚¨é—œæ–¼ã€Œèªè¨€æç¤ºå½¢å¼å½±éŸ¿ã€çš„ç ”ç©¶å•é¡Œï¼\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}